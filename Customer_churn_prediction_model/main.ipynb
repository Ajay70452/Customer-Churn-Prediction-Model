{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d54eb89",
   "metadata": {},
   "source": [
    "For this project we have used the classic \"Telco Customer Churn\" dataset. It's ideal because it contains a mix of demographic, account, and service usage information, along with a clear \"Churn\" label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c5d6cb",
   "metadata": {},
   "source": [
    "# Project: Customer Churn Prediction Model\n",
    "\n",
    "Business Goal: To build a machine learning model that accurately predicts which customers are likely to churn, enabling the Customer Success team to take proactive retention measures.\n",
    "\n",
    "Methodology:\n",
    "1.  Data Loading & Cleaning: Load the Telco dataset and handle inconsistencies.\n",
    "2.  Exploratory Data Analysis (EDA): Visualize the differences between churning and non-churning customers.\n",
    "3.  Feature Engineering & Preprocessing: Convert categorical data to numerical format and prepare it for modeling.\n",
    "4.  Model Training: Build and train a Random Forest Classifier.\n",
    "5.  Model Evaluation: Assess performance using a confusion matrix, classification report, and feature importance.\n",
    "6.  Export for BI: Generate a final predictions file for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5627e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('telco_churn.csv')\n",
    "\n",
    "print(\"Data Head:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Info:\")\n",
    "df.info()\n",
    "\n",
    "# --- Data Cleaning ---\n",
    "# TotalCharges is object type, needs to be numeric. Some values are ' '.\n",
    "# We'll treat these ' ' as missing values and impute them with the median.\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "median_total_charges = df['TotalCharges'].median()\n",
    "df['TotalCharges'].fillna(median_total_charges, inplace=True)\n",
    "\n",
    "# Drop customerID as it's not a predictive feature\n",
    "df.drop('customerID', axis=1, inplace=True)\n",
    "\n",
    "# Convert our target variable 'Churn' to binary (0/1)\n",
    "df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "print(\"\\nData after cleaning:\")\n",
    "print(df.head())\n",
    "print(f\"\\nNumber of missing values in TotalCharges after imputation: {df['TotalCharges'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a77b02",
   "metadata": {},
   "source": [
    "EDA: Understanding Churn Drivers\n",
    "Let's visualize how different features relate to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aac6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='Churn')\n",
    "plt.title('Churn Distribution')\n",
    "plt.show()\n",
    "\n",
    "print(df['Churn'].value_counts(normalize=True))\n",
    "\n",
    "# Visualize churn across key categorical features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "sns.countplot(data=df, x='Contract', hue='Churn', ax=axes[0, 0]).set_title('Churn by Contract Type')\n",
    "sns.countplot(data=df, x='TechSupport', hue='Churn', ax=axes[0, 1]).set_title('Churn by Tech Support')\n",
    "sns.countplot(data=df, x='PaymentMethod', hue='Churn', ax=axes[1, 0]).set_title('Churn by Payment Method')\n",
    "axes[1, 0].tick_params(axis='x', rotation=30)\n",
    "sns.countplot(data=df, x='InternetService', hue='Churn', ax=axes[1, 1]).set_title('Churn by Internet Service')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f4fcb",
   "metadata": {},
   "source": [
    " Data for Modeling\n",
    "Machine learning models require all input features to be numeric. We will use One-Hot Encoding this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df95983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True) # drop_first=True to avoid multicollinearity\n",
    "\n",
    "print(\"Shape of encoded features:\", X_encoded.shape)\n",
    "print(\"\\nEncoded Features Head:\")\n",
    "print(X_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77273cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80/20 split)\n",
    "# stratify=y ensures the churn distribution is the same in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Random Forest Classifier\n",
    "# class_weight='balanced' helps the model handle the imbalanced churn data\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "print(\"Training the model...\")\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a0897",
   "metadata": {},
   "source": [
    " Evaluating Model Performance\n",
    "We will use the test set, which the model has never seen before, to get an unbiased assessment of its performance. **Recall** for the 'Churn' class (1) is our key metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1] # Probability for the 'Churn' class\n",
    "\n",
    "# --- Performance Metrics ---\n",
    "print(\"--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(f\"AUC Score: {roc_auc_score(y_test, y_pred_proba):.2f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Churned', 'Churned'], yticklabels=['Not Churned', 'Churned'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b1128",
   "metadata": {},
   "source": [
    "### Identifying Key Churn Drivers\n",
    "Let's see what features the model found most predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = rf_classifier.feature_importances_\n",
    "feature_names = X_encoded.columns\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False).head(10) # Top 10\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df, palette='viridis')\n",
    "plt.title('Top 10 Churn Driver Features')\n",
    "plt.show()\n",
    "\n",
    "# --- Create the Final Output File for the Business Team ---\n",
    "# Let's predict on the ENTIRE original dataset to get a churn score for everyone\n",
    "full_predictions_proba = rf_classifier.predict_proba(X_encoded)[:, 1]\n",
    "\n",
    "# Create a final dataframe with customer info and churn score\n",
    "final_df = df.copy() # Start with the original (pre-encoded) data for readability\n",
    "final_df['Churn_Probability'] = full_predictions_proba\n",
    "final_df['Predicted_Churn'] = rf_classifier.predict(X_encoded)\n",
    "\n",
    "# Add a risk tier for easy prioritization\n",
    "def assign_risk_tier(score):\n",
    "    if score > 0.75:\n",
    "        return 'High Risk'\n",
    "    elif score > 0.50:\n",
    "        return 'Medium Risk'\n",
    "    else:\n",
    "        return 'Low Risk'\n",
    "\n",
    "final_df['Risk_Tier'] = final_df['Churn_Probability'].apply(assign_risk_tier)\n",
    "\n",
    "# Save to CSV for BI tool import\n",
    "final_df.to_csv('churn_predictions_with_scores.csv', index=False)\n",
    "\n",
    "print(\"\\nFinal predictions with scores saved to 'churn_predictions_with_scores.csv'\")\n",
    "print(final_df[['tenure', 'Contract', 'MonthlyCharges', 'Churn_Probability', 'Risk_Tier']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
